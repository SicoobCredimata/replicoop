# üåä Fluxo de Dados - ReplicOOP

## üìä Vis√£o Geral do Fluxo

O **ReplicOOP** processa dados atrav√©s de um pipeline bem definido que garante consist√™ncia e seguran√ßa durante a replica√ß√£o.

```mermaid
flowchart TD
    %% Input Phase
    A[üë§ Usu√°rio Inicia] --> B[üéØ Menu Selection]
    B --> C{üìã Validar Configura√ß√£o?}
    C -->|‚ùå Inv√°lida| D[‚ùó Exibir Erro]
    C -->|‚úÖ V√°lida| E[üîß Carregar Config]

    %% Preparation Phase  
    E --> F[üîê Estabelecer Conex√µes]
    F --> G{üíæ Conex√µes OK?}
    G -->|‚ùå Falha| H[‚ùó Erro Conex√£o]
    G -->|‚úÖ Sucesso| I[üõ°Ô∏è Criar Backup]

    %% Analysis Phase
    I --> J[üìä Analisar Estruturas]
    J --> K[üìù Comparar Diferen√ßas]
    K --> L{üîç H√° Diferen√ßas?}
    L -->|‚ùå N√£o| M[‚úÖ Sistema Atualizado]
    L -->|‚úÖ Sim| N[‚öôÔ∏è Planejar Replica√ß√£o]

    %% Execution Phase
    N --> O[üóÇÔ∏è Replicar Estruturas]
    O --> P{üìã Tabelas Maintain?}
    P -->|‚úÖ Sim| Q[üì¶ Replicar Dados]
    P -->|‚ùå N√£o| R[üìê S√≥ Estrutura]
    Q --> S[üîç Validar Resultado]
    R --> S

    %% Finalization Phase
    S --> T{‚úÖ Valida√ß√£o OK?}
    T -->|‚ùå Falha| U[üîÑ Rollback]
    T -->|‚úÖ Sucesso| V[üìä Gerar Relat√≥rio]
    V --> W[üéâ Finalizar]

    %% Error Flows
    D --> X[üìú Log Erro]
    H --> X
    U --> X
    X --> Y[üîö Terminar]
```

## üîÑ Detalhamento das Fases

### üéØ **Fase 1: Inicializa√ß√£o**

#### Entrada do Usu√°rio
```python
# Fluxo de entrada
User Input ‚Üí Menu System ‚Üí Option Validation ‚Üí Configuration Loading

# Dados processados:
- Op√ß√£o selecionada pelo usu√°rio
- Par√¢metros de configura√ß√£o
- Valida√ß√£o de credenciais
- Verifica√ß√£o de conectividade
```

#### Processamento de Configura√ß√£o
```python
def load_configuration():
    """Carrega e valida configura√ß√£o"""
    
    # 1. L√™ config.json
    config_data = json.load('config.json')
    
    # 2. Valida estrutura
    validate_config_structure(config_data)
    
    # 3. Testa conectividade
    test_database_connections(config_data)
    
    # 4. Carrega tabelas maintain
    maintain_tables = config_data.get('maintain', [])
    
    return config_data, maintain_tables
```

### üîê **Fase 2: Prepara√ß√£o**

#### Estabelecimento de Conex√µes
```mermaid
sequenceDiagram
    participant CM as ConfigManager
    participant DM as DatabaseManager
    participant ProdDB as Production DB
    participant SandDB as Sandbox DB

    CM->>DM: get_connection('production')
    DM->>ProdDB: establish_connection()
    ProdDB-->>DM: connection_established
    
    CM->>DM: get_connection('sandbox')
    DM->>SandDB: establish_connection()
    SandDB-->>DM: connection_established
    
    DM-->>CM: both_connections_ready
```

#### Cria√ß√£o de Backup
```python
def create_safety_backup():
    """Cria backup de seguran√ßa antes da replica√ß√£o"""
    
    # 1. Gera timestamp √∫nico
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # 2. Executa mysqldump
    backup_file = f"backup_{timestamp}.sql"
    mysqldump_command = build_mysqldump_command(sandbox_config, backup_file)
    
    # 3. Comprime arquivo
    compressed_file = f"{backup_file}.gz"
    compress_with_gzip(backup_file, compressed_file)
    
    # 4. Remove arquivo original
    os.remove(backup_file)
    
    return compressed_file
```

### üìä **Fase 3: An√°lise**

#### Coleta de Estruturas
```python
def analyze_database_structures():
    """Analisa estruturas dos bancos de dados"""
    
    # Estruturas do banco de produ√ß√£o
    prod_tables = get_all_tables(production_conn)
    prod_structures = {}
    
    for table in prod_tables:
        prod_structures[table] = {
            'columns': get_table_columns(production_conn, table),
            'indexes': get_table_indexes(production_conn, table),
            'foreign_keys': get_foreign_keys(production_conn, table),
            'constraints': get_table_constraints(production_conn, table)
        }
    
    # Estruturas do sandbox
    sand_tables = get_all_tables(sandbox_conn)
    sand_structures = {}
    
    for table in sand_tables:
        sand_structures[table] = get_table_structure(sandbox_conn, table)
    
    return prod_structures, sand_structures
```

#### Compara√ß√£o e Diferen√ßas
```python
def compare_structures(prod_structures, sand_structures):
    """Compara estruturas e identifica diferen√ßas"""
    
    differences = {
        'new_tables': [],      # Tabelas que precisam ser criadas
        'modified_tables': [], # Tabelas com estrutura diferente
        'deleted_tables': [],  # Tabelas que existem no sandbox mas n√£o na prod
        'new_columns': {},     # Novas colunas por tabela
        'modified_columns': {} # Colunas modificadas por tabela
    }
    
    # Identifica tabelas novas
    for table in prod_structures:
        if table not in sand_structures:
            differences['new_tables'].append(table)
        else:
            # Compara estruturas existentes
            compare_table_structures(
                table, 
                prod_structures[table], 
                sand_structures[table], 
                differences
            )
    
    return differences
```

### ‚öôÔ∏è **Fase 4: Planejamento**

#### Ordem de Execu√ß√£o
```python
def plan_replication_order(differences, maintain_tables):
    """Planeja ordem de replica√ß√£o considerando depend√™ncias"""
    
    execution_plan = {
        'phase_1_structure': [],  # Apenas estrutura
        'phase_2_data': [],       # Estrutura + dados (maintain)
        'phase_3_cleanup': []     # Limpeza e valida√ß√£o
    }
    
    # Ordena tabelas por depend√™ncias (FK)
    ordered_tables = sort_tables_by_dependencies(differences['new_tables'])
    
    for table in ordered_tables:
        if table in maintain_tables:
            execution_plan['phase_2_data'].append(table)
        else:
            execution_plan['phase_1_structure'].append(table)
    
    return execution_plan
```

### üóÇÔ∏è **Fase 5: Execu√ß√£o de Estruturas**

#### Replica√ß√£o de Estruturas
```mermaid
flowchart TD
    A[üìã Lista de Tabelas] --> B{üîç Tem FK?}
    B -->|‚úÖ Sim| C[‚ùå Remove FKs Temporariamente]
    B -->|‚ùå N√£o| D[üèóÔ∏è Criar Tabela]
    C --> D
    D --> E[üìä Criar √çndices]
    E --> F[üîß Criar Constraints]
    F --> G{üìã Mais Tabelas?}
    G -->|‚úÖ Sim| A
    G -->|‚ùå N√£o| H[üîó Recriar FKs]
    H --> I[‚úÖ Estruturas Prontas]
```

#### C√≥digo de Replica√ß√£o de Estrutura
```python
def replicate_table_structure(table_name, structure):
    """Replica estrutura de uma tabela"""
    
    try:
        # 1. Remove FKs problem√°ticas temporariamente
        foreign_keys = structure.get('foreign_keys', [])
        if foreign_keys:
            drop_foreign_keys(sandbox_conn, table_name)
        
        # 2. Drop tabela se existir
        drop_table_if_exists(sandbox_conn, table_name)
        
        # 3. Cria nova tabela
        create_table_sql = build_create_table_sql(table_name, structure)
        execute_sql(sandbox_conn, create_table_sql)
        
        # 4. Cria √≠ndices
        for index in structure.get('indexes', []):
            create_index_sql = build_create_index_sql(table_name, index)
            execute_sql(sandbox_conn, create_index_sql)
        
        # 5. Registra sucesso
        logger.info(f"Estrutura da tabela {table_name} replicada com sucesso")
        
    except Exception as e:
        logger.error(f"Erro ao replicar estrutura da tabela {table_name}: {e}")
        raise
```

### üì¶ **Fase 6: Replica√ß√£o de Dados**

#### Fluxo de Dados para Tabelas Maintain
```python
def replicate_table_data(table_name):
    """Replica dados de tabelas marcadas como maintain"""
    
    # 1. Conta registros na origem
    count_sql = f"SELECT COUNT(*) FROM {table_name}"
    total_records = execute_scalar(production_conn, count_sql)
    
    if total_records == 0:
        logger.info(f"Tabela {table_name} est√° vazia")
        return
    
    # 2. Seleciona dados em lotes
    batch_size = 1000
    offset = 0
    
    with tqdm(total=total_records, desc=f"Replicando {table_name}") as pbar:
        while offset < total_records:
            # Busca lote de dados
            select_sql = f"""
                SELECT * FROM {table_name} 
                LIMIT {batch_size} OFFSET {offset}
            """
            batch_data = execute_query(production_conn, select_sql)
            
            # Insere lote no sandbox
            if batch_data:
                insert_batch_data(sandbox_conn, table_name, batch_data)
                pbar.update(len(batch_data))
            
            offset += batch_size
    
    logger.info(f"Replica√ß√£o de dados da tabela {table_name} conclu√≠da")
```

#### Otimiza√ß√£o de Performance
```python
def optimize_data_replication():
    """Otimiza√ß√µes para performance"""
    
    # 1. Desabilita autocommit para transa√ß√µes em lote
    sandbox_conn.autocommit = False
    
    # 2. Aumenta tamanhos de buffer
    execute_sql(sandbox_conn, "SET SESSION bulk_insert_buffer_size = 268435456")
    execute_sql(sandbox_conn, "SET SESSION max_heap_table_size = 268435456")
    
    # 3. Desabilita verifica√ß√£o de FK durante inser√ß√£o
    execute_sql(sandbox_conn, "SET FOREIGN_KEY_CHECKS = 0")
    
    return lambda: restore_default_settings()
```

### üîç **Fase 7: Valida√ß√£o**

#### Valida√ß√£o de Integridade
```python
def validate_replication_integrity():
    """Valida integridade da replica√ß√£o"""
    
    validation_results = {
        'structure_validation': True,
        'data_validation': True,
        'constraint_validation': True,
        'errors': []
    }
    
    try:
        # 1. Valida estruturas
        validate_table_structures(validation_results)
        
        # 2. Valida contagem de dados (tabelas maintain)
        validate_data_counts(validation_results)
        
        # 3. Valida constraints e FKs
        validate_constraints(validation_results)
        
    except Exception as e:
        validation_results['errors'].append(str(e))
    
    return validation_results
```

### üìä **Fase 8: Relat√≥rio**

#### Gera√ß√£o de Relat√≥rio
```python
def generate_replication_report(results):
    """Gera relat√≥rio detalhado da replica√ß√£o"""
    
    report = {
        'timestamp': datetime.now(),
        'execution_time': results['end_time'] - results['start_time'],
        'tables_processed': len(results['tables']),
        'maintain_tables': len(results['maintain_tables']),
        'structure_only_tables': len(results['structure_tables']),
        'total_records_replicated': results['total_records'],
        'backup_created': results['backup_file'],
        'success': results['success'],
        'errors': results.get('errors', [])
    }
    
    # Formata relat√≥rio para exibi√ß√£o
    formatted_report = format_report_for_display(report)
    
    # Salva em arquivo
    save_report_to_file(report)
    
    return formatted_report
```

## üîÑ Fluxos de Dados Espec√≠ficos

### üíæ **Fluxo de Backup**
```
Sandbox DB ‚Üí mysqldump ‚Üí backup.sql ‚Üí gzip ‚Üí backup.sql.gz ‚Üí storage/
```

### üìä **Fluxo de Estrutura**
```
Production DB ‚Üí SHOW CREATE TABLE ‚Üí Parse Structure ‚Üí Adapt to Sandbox ‚Üí CREATE TABLE
```

### üì¶ **Fluxo de Dados (Maintain)**
```
Production DB ‚Üí SELECT * ‚Üí Batch Processing ‚Üí INSERT INTO ‚Üí Sandbox DB
```

### üìú **Fluxo de Logs**
```
Operations ‚Üí LoggerManager ‚Üí Format ‚Üí File Writer ‚Üí replicoop_YYYYMMDD.log
```

## üö® Tratamento de Erros no Fluxo

### Estrat√©gias de Recupera√ß√£o
```python
ERROR_RECOVERY_STRATEGIES = {
    'connection_error': {
        'strategy': 'retry_with_backoff',
        'max_attempts': 3,
        'backoff_factor': 2
    },
    'foreign_key_error': {
        'strategy': 'disable_fk_and_continue',
        'fallback': 'log_warning'
    },
    'data_too_large_error': {
        'strategy': 'reduce_batch_size',
        'min_batch_size': 100
    },
    'disk_space_error': {
        'strategy': 'cleanup_old_backups',
        'then': 'retry_operation'
    }
}
```

### Pontos de Checkpoint
```python
CHECKPOINTS = {
    'config_loaded': 'Configura√ß√£o carregada com sucesso',
    'connections_established': 'Conex√µes estabelecidas',
    'backup_created': 'Backup de seguran√ßa criado',
    'structures_analyzed': 'Estruturas analisadas',
    'replication_planned': 'Plano de replica√ß√£o criado',
    'structures_replicated': 'Estruturas replicadas',
    'data_replicated': 'Dados replicados',
    'validation_completed': 'Valida√ß√£o conclu√≠da',
    'operation_finished': 'Opera√ß√£o finalizada'
}
```

---

**Pr√≥ximo**: [Padr√µes de Design](design-patterns.md)